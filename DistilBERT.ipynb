{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DistilBERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MiHH4SuVogIz","executionInfo":{"status":"ok","timestamp":1649538193782,"user_tz":240,"elapsed":4798,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3feb3793-2e65-467d-c9a9-ebc470e4e8dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}],"source":["!pip install transformers\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import transformers\n","from transformers import DistilBertTokenizer\n","from transformers import TFDistilBertForSequenceClassification\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from tensorflow.keras.utils import to_categorical\n","\n","pd.set_option('display.max_colwidth', None)\n","MODEL_NAME = 'distilbert-base-uncased-finetuned-sst-2-english'# This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2.\n","BATCH_SIZE = 16\n","N_EPOCHS = 3 # we can put more, because evaluation of the model shows big difference in loss with accuracy 1.0"]},{"cell_type":"markdown","source":["## Prepare data"],"metadata":{"id":"N0hJhjzaJhnQ"}},{"cell_type":"code","source":["loaded_df = pd.read_csv('drugsComTrain_raw.tsv', sep='\\t')\n","# df = loaded_df[['review', 'rating']]\n","df = loaded_df[:10000]\n","\n","\n","def get_sentiment(rating):\n","  if rating < 4.0:\n","    return 'neg'\n","  elif rating >= 4.0 and rating <= 7.0:\n","    return 'neutral'\n","  else:\n","    return 'pos'\n","\n","df['sentiment'] = df['rating'].map(lambda x: get_sentiment(x))"],"metadata":{"id":"A-fObCrHpR3X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649538160300,"user_tz":240,"elapsed":1912,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"76fb66a9-7e65-4005-ac71-7291f46cf8b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","source":["# encode class names to integers\n","labelencoder = preprocessing.LabelEncoder()\n","labels = labelencoder.fit_transform(df['sentiment'])\n","\n","cat_labels = to_categorical(labels)\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(df['review'], cat_labels, random_state=1)\n","\n","train_texts = train_texts.to_list()\n","val_texts = val_texts.to_list()"],"metadata":{"id":"h6ZKGSEvpNSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')   # switch to MODEL_NAME\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True)"],"metadata":{"id":"qO3kPpo-pDcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(train_encodings),\n","    train_labels\n","))\n","# val_dataset = tf.data.Dataset.from_tensor_slices((\n","#     dict(val_encodings),\n","#     val_labels\n","# )) "],"metadata":{"id":"FPswZR__pHPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load test data\n","loaded_test_df = pd.read_csv('drugsComTest_raw.tsv', sep='\\t')\n","test_df = loaded_test_df[:2000]\n","\n","test_df['sentiment'] = test_df['rating'].map(lambda x: get_sentiment(x))\n","\n","# enocde test labels\n","labelencoder = preprocessing.LabelEncoder()\n","labels = labelencoder.fit_transform(test_df['sentiment'])\n","\n","cat_labels = to_categorical(labels)\n","\n","X_test = test_df['review']\n","X_test = X_test.to_list()\n","\n","y_test = cat_labels\n","\n","# tokenzie and encode dataset\n","test_encodings = tokenizer(X_test, truncation=True, padding=True)\n","test_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(test_encodings),\n","    y_test\n","))\n","\n","test_dataset\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5nSr73oJpkx","executionInfo":{"status":"ok","timestamp":1649538823600,"user_tz":240,"elapsed":9238,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"e7216f1f-50ef-4424-9ede-dcbcf08333bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n"]},{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(3,), dtype=tf.float32, name=None))>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Built and evalaute model"],"metadata":{"id":"yfkpNCyVVZH1"}},{"cell_type":"code","source":["def evaluate_model(model_obj):\n","    # get predictions with test set\n","    model2_pred = model_obj.predict(test_dataset.batch(16))\n","    model2_pred_labels = np.argmax(model2_pred.logits, axis=1)\n","    print('model2_pred_labels:', model2_pred_labels)\n","    y_test_labels = np.argmax(y_test, axis=1)\n","    print('y_test_labels:', y_test_labels)\n","    print(classification_report(y_test_labels, model2_pred_labels,target_names=labelencoder.classes_))\n"],"metadata":{"id":"rM4LCqH_LZlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSS6l6lIpJEF","outputId":"f40f20fc-4d54-4a85-d9ac-03052cf79e7d","executionInfo":{"status":"ok","timestamp":1649539197707,"user_tz":240,"elapsed":2447,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHqGZnyPu1fr","outputId":"1ce80b63-cd23-4273-95ec-3265a63b2b11","executionInfo":{"status":"ok","timestamp":1649539197710,"user_tz":240,"elapsed":76,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"tf_distil_bert_for_sequence_classification_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," distilbert (TFDistilBertMai  multiple                 66362880  \n"," nLayer)                                                         \n","                                                                 \n"," pre_classifier (Dense)      multiple                  590592    \n","                                                                 \n"," classifier (Dense)          multiple                  2307      \n","                                                                 \n"," dropout_39 (Dropout)        multiple                  0         \n","                                                                 \n","=================================================================\n","Total params: 66,955,779\n","Trainable params: 66,955,779\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["train_encodings_small = tokenizer(train_texts[:2000], truncation=True, padding=True)\n","# val_encodings_small = tokenizer(val_texts[:2000], truncation=True, padding=True)\n"],"metadata":{"id":"IhJIEFGq3nAA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset_small = tf.data.Dataset.from_tensor_slices((\n","    dict(train_encodings_small),\n","    train_labels[:2000]\n","))\n","# val_dataset_small = tf.data.Dataset.from_tensor_slices((\n","#     dict(val_encodings_small),\n","#     val_labels[:2000]\n","# )) "],"metadata":{"id":"tRPLu7m67M0p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DistilBERT"],"metadata":{"id":"fX9kYGFyVQr8"}},{"cell_type":"code","source":["model.fit(train_dataset_small.batch(16),\n","          epochs=2,\n","          batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZx4D6Gp23nw","outputId":"198b90f3-de64-4ed1-9118-a3eea0d2769f","executionInfo":{"status":"ok","timestamp":1649539695291,"user_tz":240,"elapsed":294138,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","125/125 [==============================] - 117s 857ms/step - loss: 1.1035 - categorical_accuracy: 0.5565\n","Epoch 2/2\n","125/125 [==============================] - 109s 872ms/step - loss: 1.2414 - categorical_accuracy: 0.6245\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1250643610>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["evaluate_model(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWXNQ_TGLddH","executionInfo":{"status":"ok","timestamp":1649539750662,"user_tz":240,"elapsed":38818,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"aa40ad78-d4f8-4c94-aa53-6ce67936503c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model2_pred_labels: [2 2 2 ... 2 2 2]\n","y_test_labels: [2 2 2 ... 2 0 2]\n","              precision    recall  f1-score   support\n","\n","         neg       0.67      0.47      0.55       446\n","     neutral       0.00      0.00      0.00       348\n","         pos       0.69      0.96      0.80      1206\n","\n","    accuracy                           0.69      2000\n","   macro avg       0.45      0.48      0.45      2000\n","weighted avg       0.56      0.69      0.61      2000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["# Models below were other variations"],"metadata":{"id":"lOVLJApEVCEc"}},{"cell_type":"code","source":["model_am2 = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model_am2.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])\n","\n","model_am2.fit(train_dataset_small.batch(16),\n","          epochs=1,\n","          batch_size=BATCH_SIZE)\n","evaluate_model(model_am2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxaQgFHZPJMs","executionInfo":{"status":"ok","timestamp":1649540059772,"user_tz":240,"elapsed":157710,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"3c70688c-89a3-492d-a370-ab27b2d9b192"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_59']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["125/125 [==============================] - 115s 862ms/step - loss: 1.0794 - categorical_accuracy: 0.6000\n","model2_pred_labels: [2 2 2 ... 2 2 2]\n","y_test_labels: [2 2 2 ... 2 0 2]\n","              precision    recall  f1-score   support\n","\n","         neg       0.00      0.00      0.00       446\n","     neutral       0.00      0.00      0.00       348\n","         pos       0.60      1.00      0.75      1206\n","\n","    accuracy                           0.60      2000\n","   macro avg       0.20      0.33      0.25      2000\n","weighted avg       0.36      0.60      0.45      2000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["model2 = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","# losss = tf.keras.losses.SparseCategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model2.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEWenvUKviRI","outputId":"0d319c3d-d509-4938-877e-fc9bb6750ada","executionInfo":{"status":"ok","timestamp":1649518619600,"user_tz":240,"elapsed":1118,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_39', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model2.fit(train_dataset_small.shuffle(2000).batch(16), \n","          epochs=4,\n","          batch_size=BATCH_SIZE)\n","\n","# model2.fit(train_dataset.shuffle(2000).batch(16), \n","#           epochs=4,\n","#           batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zShzd8g_qpw","outputId":"373c42f6-94a8-4535-9cc8-b81afe635fbe","executionInfo":{"status":"ok","timestamp":1649522122082,"user_tz":240,"elapsed":3421192,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","469/469 [==============================] - 834s 2s/step - loss: 1.4984 - categorical_accuracy: 0.6133\n","Epoch 2/4\n","469/469 [==============================] - 834s 2s/step - loss: 2.6460 - categorical_accuracy: 0.2957\n","Epoch 3/4\n","469/469 [==============================] - 835s 2s/step - loss: 0.9549 - categorical_accuracy: 0.1871\n","Epoch 4/4\n","469/469 [==============================] - 835s 2s/step - loss: 0.9374 - categorical_accuracy: 0.1700\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8b827d0050>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["evaluate_model(model2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XepH2jDTMiDO","executionInfo":{"status":"ok","timestamp":1649525630208,"user_tz":240,"elapsed":76836,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"62f293af-e256-44fd-aade-378713d35f74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model2_pred_labels: [1 0 0 ... 1 0 0]\n","y_test_labels: [2 2 2 ... 2 0 2]\n","              precision    recall  f1-score   support\n","\n","         neg       0.18      0.62      0.28       446\n","     neutral       0.19      0.24      0.21       348\n","         pos       0.00      0.00      0.00      1206\n","\n","    accuracy                           0.18      2000\n","   macro avg       0.12      0.28      0.16      2000\n","weighted avg       0.07      0.18      0.10      2000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["Save model"],"metadata":{"id":"XRUuqfbFNE1H"}},{"cell_type":"code","source":["# SAVE MODEL  ( https://huggingface.co/docs/transformers/main_classes/model )\n","model.save_pretrained('04-09-distilbert_model_epoch2_batch16')\n","!zip -r 04-09-distilbert_model_epoch2_batch16.zip 04-09-distilbert_model_epoch2_batch16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MXbVft2kNFyj","executionInfo":{"status":"ok","timestamp":1649540155165,"user_tz":240,"elapsed":17128,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"69be9aca-d1c6-4917-e2f1-b3d3160d9fb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: 04-09-distilbert_model_epoch2_batch16/ (stored 0%)\n","  adding: 04-09-distilbert_model_epoch2_batch16/config.json (deflated 48%)\n","  adding: 04-09-distilbert_model_epoch2_batch16/tf_model.h5 (deflated 8%)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# with open('/content/drive/My Drive/NLP Models/foo.txt', 'w') as f:\n","#   f.write('Hello Google Drive!')\n","# !cat /content/drive/My\\ Drive/NLP\\ Models/foo.txt\n","\n","!cp 04-09-distilbert_model_epoch2_batch16.zip \"/content/drive/My Drive/NLP Models/04-09-distilbert_model_epoch2_batch16.zip\""],"metadata":{"id":"skWjdte3NUT8","executionInfo":{"status":"ok","timestamp":1649540354295,"user_tz":240,"elapsed":34036,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28ffe3c9-7e1c-4c9a-c5ca-3f3b1bb1b570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Download to my local computer\n","\n","from google.colab import files\n","files.download('04-09-distilbert_model_epoch2_batch16.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"_PBc6wC5NbEb","executionInfo":{"status":"ok","timestamp":1649540268577,"user_tz":240,"elapsed":342,"user":{"displayName":"Anne Mei","userId":"01502389685547062085"}},"outputId":"267442bf-5e20-4491-b7aa-8cec126d797d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a1c92ed9-7315-4b4b-a7ab-fab4231d37aa\", \"04-09-distilbert_model_epoch2_batch16.zip\", 246798972)"]},"metadata":{}}]},{"cell_type":"markdown","source":["Evaluate model with test data"],"metadata":{"id":"CAFkhdErMOlR"}},{"cell_type":"code","source":["model2.save('61_acc_distilbert.model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HubHkIYA_ya4","outputId":"c70fde12-8580-473d-ee3c-9fe0cb1905e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a79504f90>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a7950ebd0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a79522990>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a794b6650>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a794cb3d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x7f6a794df150>, because it is not built.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: 61_acc_distilbert.model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: 61_acc_distilbert.model/assets\n"]}]},{"cell_type":"code","source":["model3 = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","# losss = tf.keras.losses.SparseCategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model3.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])\n","\n","model3.fit(train_dataset_small.shuffle(2000).batch(16), \n","          epochs=12,\n","          batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"id":"2MNm7YEXS4k1","outputId":"c1433a0d-67bb-4018-d90b-882167ab5197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_179', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","125/125 [==============================] - 185s 1s/step - loss: 7.9257 - categorical_accuracy: 0.5805\n","Epoch 2/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.6249 - categorical_accuracy: 0.6140\n","Epoch 3/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.5118 - categorical_accuracy: 0.6140\n","Epoch 4/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.4151 - categorical_accuracy: 0.6140\n","Epoch 5/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.3828 - categorical_accuracy: 0.6140\n","Epoch 6/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.2942 - categorical_accuracy: 0.6140\n","Epoch 7/12\n","125/125 [==============================] - 174s 1s/step - loss: 6.3667 - categorical_accuracy: 0.6140\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-d9cd80ee85fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model3.fit(train_dataset_small.shuffle(2000).batch(16), \n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           batch_size=BATCH_SIZE)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model4 = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=4e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","# losss = tf.keras.losses.SparseCategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model4.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])\n","\n","model4.fit(train_dataset_small.shuffle(2000).batch(16), \n","          epochs=12,\n","          batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQZBMCx4VvB7","outputId":"fc2c7b70-a897-4e13-9e46-c11b5614fbcd"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_199']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","125/125 [==============================] - 190s 1s/step - loss: 1.5397 - categorical_accuracy: 0.1720\n","Epoch 2/12\n","125/125 [==============================] - 174s 1s/step - loss: 10.8664 - categorical_accuracy: 0.4095\n","Epoch 3/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3685\n","Epoch 4/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3625\n","Epoch 5/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3535\n","Epoch 6/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3555\n","Epoch 7/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3619 - categorical_accuracy: 0.3690\n","Epoch 8/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3619 - categorical_accuracy: 0.3570\n","Epoch 9/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3861 - categorical_accuracy: 0.3445\n","Epoch 10/12\n","125/125 [==============================] - 174s 1s/step - loss: 13.3780 - categorical_accuracy: 0.3445\n","Epoch 11/12\n","125/125 [==============================] - 175s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3605\n","Epoch 12/12\n","125/125 [==============================] - 175s 1s/step - loss: 13.3700 - categorical_accuracy: 0.3830\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6af5adf4d0>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["model5 = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=4e-5)\n","losss = tf.keras.losses.CategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","# losss = tf.keras.losses.SparseCategoricalCrossentropy() # Computes the crossentropy loss between the labels and predictions. \n","model5.compile(optimizer=optimizer, loss=losss, metrics=['categorical_accuracy'])\n","\n","train_sample = train_dataset.take(2000)\n","\n","model5.fit(train_sample.shuffle(2000).batch(8), \n","          epochs=3,\n","          batch_size=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QkdjXmHla780","outputId":"23c2af15-4d96-4638-f621-32397b064ab7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_299', 'classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","250/250 [==============================] - 238s 913ms/step - loss: 10.9404 - categorical_accuracy: 0.2565\n","Epoch 2/3\n","250/250 [==============================] - 227s 908ms/step - loss: 13.3216 - categorical_accuracy: 0.2445\n","Epoch 3/3\n","250/250 [==============================] - 227s 909ms/step - loss: 13.3297 - categorical_accuracy: 0.2535\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6a6addb310>"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["train_dataset.take(2000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dcd1d5oLmEOa","outputId":"668c1c39-4d18-4824-9dbc-9b09b135d863"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(3,), dtype=tf.float32, name=None))>"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["print(train_dataset.take(2000).as_numpy_iterator())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EqLuP4O_kf5","outputId":"bee4c29f-3c6d-4130-e626-b0a1a383449f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<tensorflow.python.data.ops.dataset_ops._NumpyIterator object at 0x7f6a6ab7c410>\n"]}]}]}